{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YBjQ5_-fDgsz"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","from glob import glob\n","from PIL import Image, ImageOps\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","def load_SICE_dataset(src_dir, dst_dir_low, dst_dir_high):\n","    os.makedirs(dst_dir_low, exist_ok=True)\n","    os.makedirs(dst_dir_high, exist_ok=True)\n","    for dir_name in os.listdir(src_dir):\n","        subdir_path = os.path.join(src_dir, dir_name)\n","        \n","        if os.path.isdir(subdir_path) and dir_name not in [\"low\", \"high\"]:\n","            images = [f for f in os.listdir(subdir_path) if f.endswith('.JPG')]\n","\n","            images.sort(key=lambda f: int(os.path.splitext(f)[0]))\n","\n","            for img in images[:-1]:\n","                img_path = os.path.join(subdir_path, img)\n","                dst_path_low = os.path.join(dst_dir_low, f\"{dir_name}_{img}\")\n","                shutil.copy(img_path, dst_path_low)\n","            \n","                highest_img_path = os.path.join(subdir_path, images[-1])\n","                dst_path_high = os.path.join(dst_dir_high, f\"{dir_name}_{img}\")\n","                shutil.copy(highest_img_path, dst_path_high)\n"],"metadata":{"id":"mq0moybRWi3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVBqWrrSDzzm"},"outputs":[],"source":["!gdown https://drive.google.com/uc?id=1HiLtYiyT9R7dR9DRTLRlUUrAicC4zzWN # SICE Part 1\n","!pip install unrar\n","!unrar x Dataset_Part1.rar"]},{"cell_type":"code","source":["load_SICE_dataset(\"./Dataset_Part1\", \"./data/SICE1/low\", \"./data/SICE1/high\")"],"metadata":{"id":"Y4q6egLia9VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -r Dataset_Part1\n","!rm Dataset_Part1.rar"],"metadata":{"id":"QWZdDW2CYrFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=16VoHNPAZ5Js19zspjFOsKiGRrfkDgHoN # SICE Part 2\n","!unrar x Dataset_Part2.rar"],"metadata":{"id":"SFmg83a-ZPUf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_SICE_dataset(\"./Dataset_Part2\", \"./data/SICE2/low\", \"./data/SICE2/high\")"],"metadata":{"id":"Z6P5xI_eZPa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -r Dataset_Part2\n","!rm Dataset_Part2.rar"],"metadata":{"id":"zn2JrZgIa-pm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=0B_FjaR958nw_eHhvUUN6MzBCQXc # DICM\n","!unzip datasets__DICM.zip"],"metadata":{"id":"z2XKIOo8briS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=0B_FjaR958nw_QUpMeFlmYW5MUVE # LIME\n","!unzip datasets__LIME.zip"],"metadata":{"id":"p2YxaU8scJLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxZwjU8iD2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684146416705,"user_tz":-180,"elapsed":2584,"user":{"displayName":"Catalin","userId":"16988798672554540152"}},"outputId":"71063bed-f574-4b24-bfb9-53e7ec00b87b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset: <_BatchDataset element_spec=TensorSpec(shape=(8, 512, 512, 3), dtype=tf.float32, name=None)>\n","Validation Dataset: <_BatchDataset element_spec=TensorSpec(shape=(8, 512, 512, 3), dtype=tf.float32, name=None)>\n"]}],"source":["IMAGE_SIZE = 512\n","BATCH_SIZE = 8\n","MAX_TRAIN_IMAGES = 2422\n","\n","\n","def load_data(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n","    image = image / 255.0\n","    return image\n","\n","\n","def data_generator(low_light_images):\n","    dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n","    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","    return dataset\n","\n","train_low_light_images = sorted(glob(\"./data/SICE1/low/*\"))[:MAX_TRAIN_IMAGES]\n","val_low_light_images = sorted(glob(\"./data/SICE1/low/*\"))[MAX_TRAIN_IMAGES:]\n","\n","\n","train_dataset = data_generator(train_low_light_images)\n","val_dataset = data_generator(val_low_light_images)\n","\n","print(\"Train Dataset:\", train_dataset)\n","print(\"Validation Dataset:\", val_dataset)"]},{"cell_type":"code","source":["!pip install tensorflow-addons\n","import tensorflow_addons as tfa"],"metadata":{"id":"W0gv84fceq7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eviz5ti7D5d9"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Multiply, Reshape, Permute, Lambda\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.initializers import Zeros, Ones\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","\n","class SALayer(layers.Layer):\n","    def __init__(self, channel, groups=None, **kwargs):\n","        super(SALayer, self).__init__(**kwargs)\n","        if groups is None:\n","            groups = 1\n","        self.groups = groups\n","        self.avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n","        self.cweight = self.add_weight(shape=(1, 1, 1, channel // (2 * groups)), initializer=\"zeros\", trainable=True)\n","        self.cbias = self.add_weight(shape=(1, 1, 1, channel // (2 * groups)), initializer=\"ones\", trainable=True)\n","        self.sweight = self.add_weight(shape=(1, 1, 1, channel // (2 * groups)), initializer=\"zeros\", trainable=True)\n","        self.sbias = self.add_weight(shape=(1, 1, 1, channel // (2 * groups)), initializer=\"ones\", trainable=True)\n","        self.sigmoid = layers.Activation(\"sigmoid\")\n","        self.gn = tfa.layers.GroupNormalization(groups=channel // (2 * groups)) \n","\n","\n","    @staticmethod\n","    def channel_shuffle(x, groups):\n","        shape = tf.shape(x)\n","        b, h, w, c = shape[0], shape[1], shape[2], shape[3]\n","\n","        x = tf.reshape(x, [b, groups, h, w, c])\n","        x = tf.transpose(x, [0, 2, 3, 4, 1])\n","\n","        x = tf.reshape(x, [b, h, w, c])\n","\n","        return x\n","\n","    def call(self, inputs):\n","        shape = tf.shape(inputs)\n","        b, h, w, c = shape[0], shape[1], shape[2], shape[3]\n","        x = tf.reshape(inputs, [b * self.groups, h, w, c])\n","        x_0, x_1 = tf.split(x, num_or_size_splits=2, axis=1)\n","        \n","        xn = self.avg_pool(x_0)\n","        xn = self.cweight * xn + self.cbias\n","        xn = self.sigmoid(xn)\n","        xn = x_0 * xn\n","\n","        xs = self.gn(x_1)\n","        xs = self.sweight * xs + self.sbias\n","        xs = self.sigmoid(xs)\n","        xs = x_1 * xs\n","\n","        out = tf.concat([xn, xs], axis=1)\n","        out = tf.reshape(out, [b, h, w, c])\n","        out = self.channel_shuffle(out, self.groups)\n","        return out\n","\n","\n","def ghost_module(input_tensor, output_channels):\n","    conv1x1 = layers.Conv2D(\n","        output_channels // 4, (1, 1), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(input_tensor)\n","    conv3x3 = layers.Conv2D(\n","        output_channels // 4, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv1x1)\n","    return layers.Concatenate()([conv1x1, conv3x3])\n","\n","def build_dce_net():\n","    input_img = layers.Input(shape=(None, None, 3))\n","    ghost1 = ghost_module(input_img, 32)\n","    sa1 = SALayer(32)(ghost1)\n","    half_ghost1 = layers.Lambda(lambda x: x[:, :, :, :3 // 2])(sa1)\n","    ghost2 = ghost_module(sa1, 16)\n","    sa2 = SALayer(16)(ghost2)\n","    ghost3 = ghost_module(sa2, 16)\n","    sa3 = SALayer(16)(ghost3)\n","    ghost4 = ghost_module(sa3, 16)\n","    sa4 = SALayer(16)(ghost4)\n","    skip_conn1 = layers.Concatenate(axis=-1)([sa4, sa3])\n","    ghost5 = ghost_module(skip_conn1, 16)\n","    sa5 = SALayer(16)(ghost5)\n","    skip_conn2 = layers.Concatenate(axis=-1)([sa5, sa2])\n","    ghost6 = ghost_module(skip_conn2, 16)\n","    sa6 = SALayer(16)(ghost6)\n","    skip_conn3 = layers.Concatenate(axis=-1)([sa6, sa1])\n","    ghost7 = ghost_module(skip_conn3, 32)\n","    sa7 = SALayer(32)(ghost7)\n","    skip_conn4 = layers.Concatenate(axis=-1)([sa7, half_ghost1])\n","    x_r = layers.SeparableConv2D(3, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(skip_conn4)\n","    return keras.Model(inputs=input_img, outputs=x_r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kVb9CXaD9Tr"},"outputs":[],"source":["def color_constancy_loss(x):\n","    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n","    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]\n","    d_rg = tf.square(mr - mg)\n","    d_rb = tf.square(mr - mb)\n","    d_gb = tf.square(mb - mg)\n","    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2rY46t47D_7m"},"outputs":[],"source":["def exposure_loss(x, mean_val=0.6):\n","    x = tf.reduce_mean(x, axis=3, keepdims=True)\n","    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n","    return tf.reduce_mean(tf.square(mean - mean_val))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxLLaTDcECXq"},"outputs":[],"source":["def illumination_smoothness_loss(x):\n","    batch_size = tf.shape(x)[0]\n","    h_x = tf.shape(x)[1]\n","    w_x = tf.shape(x)[2]\n","    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n","    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n","    h_tv = tf.reduce_sum(tf.square((x[:, 1:, :, :] - x[:, : h_x - 1, :, :])))\n","    w_tv = tf.reduce_sum(tf.square((x[:, :, 1:, :] - x[:, :, : w_x - 1, :])))\n","    batch_size = tf.cast(batch_size, dtype=tf.float32)\n","    count_h = tf.cast(count_h, dtype=tf.float32)\n","    count_w = tf.cast(count_w, dtype=tf.float32)\n","    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BxUJy9SEEqD"},"outputs":[],"source":["class SpatialConsistencyLoss(keras.losses.Loss):\n","    def __init__(self, **kwargs):\n","        super().__init__(reduction=\"none\")\n","\n","        self.left_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.right_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.up_kernel = tf.constant(\n","            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.down_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n","        )\n","\n","    def call(self, y_true, y_pred):\n","\n","        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n","        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n","        original_pool = tf.nn.avg_pool2d(\n","            original_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","        enhanced_pool = tf.nn.avg_pool2d(\n","            enhanced_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","\n","        d_original_left = tf.nn.conv2d(\n","            original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_right = tf.nn.conv2d(\n","            original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_up = tf.nn.conv2d(\n","            original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_down = tf.nn.conv2d(\n","            original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","\n","        d_enhanced_left = tf.nn.conv2d(\n","            enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_right = tf.nn.conv2d(\n","            enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_up = tf.nn.conv2d(\n","            enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_down = tf.nn.conv2d(\n","            enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","\n","        d_left = tf.square(d_original_left - d_enhanced_left)\n","        d_right = tf.square(d_original_right - d_enhanced_right)\n","        d_up = tf.square(d_original_up - d_enhanced_up)\n","        d_down = tf.square(d_original_down - d_enhanced_down)\n","        return d_left + d_right + d_up + d_down\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCeUKZzjEIFC"},"outputs":[],"source":["class SAZeroDCETiny(keras.Model):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.dce_model = build_dce_net()\n","\n","    def compile(self, learning_rate, **kwargs):\n","        super().compile(**kwargs)\n","        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n","\n","    def get_enhanced_image(self, data, output):\n","        r = output\n","        enhanced_image = data\n","        for _ in range(8):\n","          enhanced_image = enhanced_image + r * (tf.square(enhanced_image) - enhanced_image)\n","        return enhanced_image\n","\n","    def call(self, data):\n","        dce_net_output = self.dce_model(data)\n","        return self.get_enhanced_image(data, dce_net_output)\n","\n","    def compute_losses(self, data, output):\n","        enhanced_image = self.get_enhanced_image(data, output)\n","        loss_illumination = 200 * illumination_smoothness_loss(output)\n","        loss_spatial_constancy = tf.reduce_mean(\n","            self.spatial_constancy_loss(enhanced_image, data)\n","        )\n","        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(enhanced_image))\n","        loss_exposure = 10 * tf.reduce_mean(exposure_loss(enhanced_image))\n","        total_loss = (\n","            loss_illumination\n","            + loss_spatial_constancy\n","            + loss_color_constancy\n","            + loss_exposure\n","        )\n","        return {\n","            \"total_loss\": total_loss,\n","            \"illumination_smoothness_loss\": loss_illumination,\n","            \"spatial_constancy_loss\": loss_spatial_constancy,\n","            \"color_constancy_loss\": loss_color_constancy,\n","            \"exposure_loss\": loss_exposure,\n","        }\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            output = self.dce_model(data)\n","            losses = self.compute_losses(data, output)\n","        gradients = tape.gradient(\n","            losses[\"total_loss\"], self.dce_model.trainable_weights\n","        )\n","        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n","        return losses\n","\n","    def test_step(self, data):\n","        output = self.dce_model(data)\n","        return self.compute_losses(data, output)\n","\n","    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n","        \"\"\"While saving the weights, we simply save the weights of the DCE-Net\"\"\"\n","        self.dce_model.save_weights(\n","            filepath, overwrite=overwrite, save_format=save_format, options=options\n","        )\n","\n","    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n","        \"\"\"While loading the weights, we simply load the weights of the DCE-Net\"\"\"\n","        self.dce_model.load_weights(\n","            filepath=filepath,\n","            by_name=by_name,\n","            skip_mismatch=skip_mismatch,\n","            options=options,\n","        )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOQHvSEfEMWq"},"outputs":[],"source":["zero_dce_model = ZeroDCE()\n","zero_dce_model.compile(learning_rate=1e-4)\n","history = zero_dce_model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n","\n","\n","def plot_result(item):\n","    plt.plot(history.history[item], label=item)\n","    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(item)\n","    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n","    plt.legend()\n","    plt.grid()\n","    plt.show()\n","\n","\n","plot_result(\"total_loss\")\n","plot_result(\"illumination_smoothness_loss\")\n","plot_result(\"spatial_constancy_loss\")\n","plot_result(\"color_constancy_loss\")\n","plot_result(\"exposure_loss\")\n"]},{"cell_type":"code","source":["# zero_dce_model.build((None, 256, 256, 3))\n","# zero_dce_model.summary()"],"metadata":{"id":"S0YUarc4Hvg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6n94cbpLESDh"},"outputs":[],"source":["def plot_results(images, titles, figure_size=(12, 12)):\n","    fig = plt.figure(figsize=figure_size)\n","    for i in range(len(images)):\n","        fig.add_subplot(1, len(images), i + 1).set_title(titles[i])\n","        _ = plt.imshow(images[i])\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","\n","def infer(original_image):\n","    image = keras.preprocessing.image.img_to_array(original_image)\n","    image = image.astype(\"float32\") / 255.0\n","    image = np.expand_dims(image, axis=0)\n","    output_image = zero_dce_model(image)\n","    output_image = tf.cast((output_image[0, :, :, :] * 255), dtype=np.uint8)\n","    output_image = Image.fromarray(output_image.numpy())\n","    return output_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XP9F01JKESuN"},"outputs":[],"source":["for val_image_file in val_low_light_images[:5]:\n","    original_image = Image.open(val_image_file)\n","    enhanced_image = infer(original_image)\n","    plot_results(\n","        [original_image, ImageOps.autocontrast(original_image), enhanced_image],\n","        [\"Original\", \"PIL Autocontrast\", \"Enhanced\"],\n","        (20, 12),\n","    )\n"]},{"cell_type":"code","source":["test_low_light_images = sorted(glob(\"./data/SICE2/low/*\"))[:2300]\n","test_low_light_images += sorted(glob(\"./data/DICM/low/*\"))[:64]\n","test_low_light_images += sorted(glob(\"./data/LIME/low/*\"))[:10]\n","\n","test_high_light_images = sorted(glob(\"./data/SICE2/high/*\"))[:2300]\n","test_high_light_images += sorted(glob(\"./data/DICM/high/*\"))[:64]\n","test_high_light_images += sorted(glob(\"./data/LIME/high/*\"))[:10]\n"],"metadata":{"id":"dX_QOvuJbQEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage.measure import structural_similarity, peak_signal_noise_ratio\n","from tensorflow.keras.utils import img_to_array\n","import numpy as np\n","\n","def calculate_psnr(img1, img2):\n","    img1 = img_to_array(img1)\n","    img2 = img_to_array(img2)\n","    return peak_signal_noise_ratio(img1, img2, data_range=img1.max() - img1.min())\n","\n","def calculate_ssim(img1, img2):\n","    img1 = img_to_array(img1)\n","    img2 = img_to_array(img2)\n","    return structural_similarity(img1, img2, multichannel=True)\n","\n","def calculate_mae(img1, img2):\n","    img1 = img_to_array(img1)\n","    img2 = img_to_array(img2)\n","    return np.mean(np.abs(img1 - img2))"],"metadata":{"id":"rd1OvQi0HhkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_psnr, total_ssim, total_mae = 0, 0, 0\n","num_images = len(test_low_light_images)\n","\n","for idx, val_image_file in enumerate(test_low_light_images):\n","    original_low_image = Image.open(val_image_file)\n","    enhanced_image = infer(original_image)\n","    original_high_image = Image.open(test_high_light_images[idx])\n","\n","    psnr = calculate_psnr(original_high_image, enhanced_image)\n","    ssim = calculate_ssim(original_high_image, enhanced_image)\n","    mae = calculate_mae(original_high_image, enhanced_image)\n","\n","    total_psnr += psnr\n","    total_ssim += ssim\n","    total_mae += mae\n","\n","avg_psnr = total_psnr / num_images\n","avg_ssim = total_ssim / num_images\n","avg_mae = total_mae / num_images\n","\n","print(\"Average PSNR:\", avg_psnr)\n","print(\"Average SSIM:\", avg_ssim)\n","print(\"Average MAE:\", avg_mae)\n"],"metadata":{"id":"JIWLmsm4hI0_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZiyLGBiPNnt"},"outputs":[],"source":["model_save_path = \"sa_zero_dce_tiny_model.h5\"\n","zero_dce_model.save_weights(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sUVmvwaPe8S"},"outputs":[],"source":["import tensorflow as tf\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(zero_dce_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model = converter.convert()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_vvC0a3PoBF"},"outputs":[],"source":["with open(\"sa_zero_dce_tiny_model.tflite\", \"wb\") as f:\n","    f.write(tflite_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7VNP8yXW7Sq"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","interpreter = tf.lite.Interpreter(model_path='sa_zero_dce_tiny_512x512.tflite')\n","\n","interpreter.allocate_tensors()\n","\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKQkye9aX9Wg"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","from skimage.transform import resize\n","\n","def infer_tflite(original_image, interpreter):\n","    image = np.array(original_image)\n","\n","    image = image.astype(\"float32\") / 255.0\n","\n","    image = np.expand_dims(image, axis=0)\n","\n","    image = resize(image, (512,512, 3))\n","\n","    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], image)\n","\n","    interpreter.invoke()\n","\n","    output_image = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n","\n","    output_image = (output_image[0] * 255).astype(np.uint8)\n","\n","    output_image = Image.fromarray(output_image)\n","\n","    return output_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ar4WrAg6YBtA"},"outputs":[],"source":["for val_image_file in test_low_light_images[:1]:\n","    original_image = Image.open(val_image_file)\n","    enhanced_image = infer_tflite(original_image, interpreter)\n","    plot_results(\n","        [original_image, ImageOps.autocontrast(original_image), enhanced_image],\n","        [\"Original\", \"PIL Autocontrast\", \"Enhanced\"],\n","        (20, 12),\n","    )\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}